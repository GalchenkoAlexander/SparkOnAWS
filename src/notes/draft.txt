Exception in thread "main" java.lang.IllegalArgumentException:
Required executor memory (1024), overhead (384 MB), and PySpark memory (0 MB)
is above the max threshold (1024 MB) of this cluster! Please check the values
of 'yarn.scheduler.maximum-allocation-mb' and/or 'yarn.nodemanager.resource.memory-mb'.

yarn.scheduler.maximum-allocation-mb
yarn.scheduler.minimum-allocation-mb
yarn.nodemanager.resource.memory-mb

cat /etc/hadoop/conf/yarn-site.xml | grep yarn.scheduler -A 2 | grep allocation-mb -A 2

spark.executor.memory + spark.executor.memoryOverhead + spark.executor.pyspark.memory > maxMem

maxMem = 1024 MB
spark.executor.memory = 1024
spark.executor.memoryOverhead = 384 MB
spark.executor.pyspark.memor = 0